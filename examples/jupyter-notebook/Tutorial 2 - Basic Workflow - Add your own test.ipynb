{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc5b948-4919-47fe-9598-0d4c1bfaf8ea",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Basic Workflow - Add Your Own Tests \n",
    "\n",
    "**Scenario**: \n",
    "\n",
    "You have developed a chatbot and you want to test how it performs for your unique use case.\n",
    "\n",
    "In this case, you have already identified a set of questions to test your chatbot and their correct answers. You want to use Moonshot to administer these tests to your chatbot to benchmark its performance.\n",
    "\n",
    "How can you add your custom dataset into Moonshot and run it with your system?\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Add your own `dataset` into Moonshot\n",
    "    1. Create the dataset manually.\n",
    "    2. Convert the csv dataset to Moonshot dataset through API.\n",
    "    3. Downloading hugging face dataset to Moonshot dataset through API.\n",
    "- Create and run your own `recipe`\n",
    "- Create and run your own `cookbook`\n",
    "\n",
    "Prerequisite:\n",
    "\n",
    "1. You have added your OpenAI connector configuration named `my-openai-endpoint` in Moonshot. If you are unsure how to do it, please refer to \"<b>Tutorial 1</b>\" in the same folder.\n",
    "\n",
    "**Before starting this tutorial, please make sure you have already installed `moonshot` and `moonshot-data`.**<br>\n",
    "Otherwise, please refer to \"<b>Moonshot - Pre-Req - Setup.ipynb</b>\" to install and configure Moonshot first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb78f9e-6842-4524-add7-7434687cc7cc",
   "metadata": {},
   "source": [
    "## Import and configure Moonshot\n",
    "\n",
    "In this section, we prepare our Jupyter notebook environment by importing necessary libraries required to execute an existing benchmark.\n",
    "\n",
    "> ⚠️ **Note:** Check that `moonshot_data_path` below matches the location where you installed `moonshot-data` and edit the code to match your location if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbde151f-34fb-4e52-88cc-62c87834cea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtejada/Dev/ai_rator_tools/aigs_moonshot/moonshot/examples/jupyter-notebook/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Python built-ins:\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# IF you're running this notebook from the moonshot/examples/jupyter-notebook folder, the below\n",
    "# line will enable you to import moonshot from the local source code. If you installed moonshot\n",
    "# from pip, you can remove this:\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "# Import moonshot utilities:\n",
    "from moonshot.api import (\n",
    "    api_create_recipe,\n",
    "    api_create_cookbook,\n",
    "    api_convert_dataset,\n",
    "    api_download_dataset,\n",
    "    api_load_runner,\n",
    "    api_set_environment_variables\n",
    ")\n",
    "\n",
    "# Environment Configuration\n",
    "# Here we set up the environment variables for the Moonshot framework.\n",
    "# These variables define the paths to various modules and components used by Moonshot,\n",
    "# organizing the framework's structure and access points.\n",
    "\n",
    "# modify moonshot_data_path to point to your own copy of moonshot-data\n",
    "moonshot_data_path = \"./moonshot-data\"\n",
    "env = {\n",
    "    \"ATTACK_MODULES\": os.path.join(moonshot_data_path, \"attack-modules\"),\n",
    "    \"BOOKMARKS\": os.path.join(moonshot_data_path, \"generated-outputs/bookmarks\"),\n",
    "    \"CONNECTORS\": os.path.join(moonshot_data_path, \"connectors\"),\n",
    "    \"CONNECTORS_ENDPOINTS\": os.path.join(moonshot_data_path, \"connectors-endpoints\"),\n",
    "    \"CONTEXT_STRATEGY\": os.path.join(moonshot_data_path, \"context-strategy\"),\n",
    "    \"COOKBOOKS\": os.path.join(moonshot_data_path, \"cookbooks\"),\n",
    "    \"DATABASES\": os.path.join(moonshot_data_path, \"generated-outputs/databases\"),\n",
    "    \"DATABASES_MODULES\": os.path.join(moonshot_data_path, \"databases-modules\"),\n",
    "    \"DATASETS\": os.path.join(moonshot_data_path, \"datasets\"),\n",
    "    \"IO_MODULES\": os.path.join(moonshot_data_path, \"io-modules\"),\n",
    "    \"METRICS\": os.path.join(moonshot_data_path, \"metrics\"),\n",
    "    \"PROMPT_TEMPLATES\": os.path.join(moonshot_data_path, \"prompt-templates\"),\n",
    "    \"RECIPES\": os.path.join(moonshot_data_path, \"recipes\"),\n",
    "    \"RESULTS\": os.path.join(moonshot_data_path, \"generated-outputs/results\"),\n",
    "    \"RESULTS_MODULES\": os.path.join(moonshot_data_path, \"results-modules\"),\n",
    "    \"RUNNERS\": os.path.join(moonshot_data_path, \"generated-outputs/runners\"),\n",
    "    \"RUNNERS_MODULES\": os.path.join(moonshot_data_path, \"runners-modules\"),\n",
    "}\n",
    "\n",
    "# Check user has set moonshot_data_path correctly:\n",
    "if not os.path.isdir(env[\"ATTACK_MODULES\"]):\n",
    "    raise ValueError(\n",
    "        \"Configured path %s does not exist. Is moonshot-data installed at %s?\"\n",
    "        % (env[\"ATTACK_MODULES\"], moonshot_data_path)\n",
    "    )\n",
    "\n",
    "# Apply the environment variables to configure the Moonshot framework.\n",
    "api_set_environment_variables(env)\n",
    "\n",
    "# Note: there might be some warning on IProgress not found. we can ignore it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df293d-0758-45cd-9181-cfc5ea39d7ff",
   "metadata": {},
   "source": [
    "## Prepare the Dataset\n",
    "\n",
    "In this section, we show how to prepare Moonshot dataset.\n",
    "\n",
    "Suppose you have a list of \"fruits\" questions to ask your chatbot, you need to prepare them into the data schema that is compatible with Moonshot.\n",
    "\n",
    "- `name` (str): name of the data\n",
    "- `description` (str): description of the dataset\n",
    "- `license` (str): license of the data\n",
    "- `reference` (str): a link/reference to where the dataset is from (or author of the dataset)\n",
    "- `examples` (list): A list of dictionary containing the prompt (`input`) and ground truth (`target`).<br>\n",
    "A `target` can be left blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c801e9-4050-4dbb-ba42-22e31d5458d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'test-dataset' has been created.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = {\n",
    "    \"name\": \"Fruits Dataset\",\n",
    "    \"description\":\"Measures whether the model knows what is a fruit\",\n",
    "    \"license\": \"MIT license\",\n",
    "    \"reference\": \"\",\n",
    "    \"examples\": [\n",
    "        {\n",
    "            \"input\": \"Is Lemon a Fruit? Answer Yes or No.\",\n",
    "            \"target\": \"Yes.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
    "            \"target\": \"Yes.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Is Bak Choy a Fruit? Answer Yes or No.\",\n",
    "            \"target\": \"No.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Is Bak Kwa a Fruit? Answer Yes or No.\",\n",
    "            \"target\": \"No.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Is Dragonfruit a Fruit? Answer Yes or No.\",\n",
    "            \"target\": \"Yes.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Is Orange a Fruit? Answer Yes or No.\",\n",
    "            \"target\": \"Yes.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Is Coke Zero a Fruit? Answer Yes or No.\",\n",
    "            \"target\": \"No.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "in_file = f\"{moonshot_data_path}/datasets/test-dataset.json\"\n",
    "json.dump(test_dataset, open(in_file, \"w+\"), indent=2)\n",
    "if os.path.exists(in_file):\n",
    "     print(f\"Dataset 'test-dataset' has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bad1e0",
   "metadata": {},
   "source": [
    "### Convert CSV dataset to Moonshot dataset\n",
    "\n",
    "You are able to convert a CSV file to a Moonshot dataset.\n",
    "\n",
    "This can be useful if you have data in CSV format and want to use it for benchmarking in Moonshot.\n",
    "\n",
    "By converting the CSV to the required JSON format, you can easily integrate your data into the Moonshot framework and run your tests seamlessly.\n",
    "\n",
    "Let's take a look at a sample csv file (`jupyter-assets-csv-file.csv`) that contains our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33190fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input,target\n",
      "\"Is Lemon a Fruit? Answer Yes or No.\",\"Yes.\"\n",
      "\"Is Apple a Fruit? Answer Yes or No.\",\"Yes.\"\n",
      "\"Is Bak Choy a Fruit? Answer Yes or No.\",\"No.\"\n",
      "\"Is Bak Kwa a Fruit? Answer Yes or No.\",\"No.\"\n",
      "\"Is Dragonfruit a Fruit? Answer Yes or No.\",\"Yes.\"\n",
      "\"Is Orange a Fruit? Answer Yes or No.\",\"Yes.\"\n",
      "\"Is Coke Zero a Fruit? Answer Yes or No.\",\"No.\"\n"
     ]
    }
   ],
   "source": [
    "with open(\"assets/jupyter-assets-csv-file.csv\", \"r\") as file:\n",
    "    csv_content = file.read()\n",
    "print(csv_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f63cad",
   "metadata": {},
   "source": [
    "We will use the following provided `api_convert_dataset` API function.\n",
    "\n",
    "- `name` (str): name of the data\n",
    "- `description` (str): description of the dataset\n",
    "- `reference` (str): a link/reference to where the dataset is from (or author of the dataset)\n",
    "- `license` (str): license of the data\n",
    "- `examples` (list): A list of dictionary containing the prompt (`input`) and ground truth (`target`).<br>\n",
    "A `target` can be left blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920542f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moonshot-data/datasets/fruits-csv-dataset.json'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_convert_dataset(\n",
    "    name=\"Fruits CSV Dataset\",\n",
    "    description=\"Measures whether the model knows what is a fruit\",\n",
    "    reference=\"\",\n",
    "    license=\"MIT license\",\n",
    "    file_path=\"assets/jupyter-assets-csv-file.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93acc02b",
   "metadata": {},
   "source": [
    "Let's take a look at what the converted dataset `fruits-csv-dataset.json` contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6e7410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"fruits-csv-dataset\",\n",
      "  \"name\": \"Fruits CSV Dataset\",\n",
      "  \"description\": \"Measures whether the model knows what is a fruit\",\n",
      "  \"reference\": \"\",\n",
      "  \"license\": \"MIT license\",\n",
      "  \"examples\": [\n",
      "    {\"input\": \"Is Lemon a Fruit? Answer Yes or No.\", \"target\": \"Yes.\"},\n",
      "    {\"input\": \"Is Apple a Fruit? Answer Yes or No.\", \"target\": \"Yes.\"},\n",
      "    {\"input\": \"Is Bak Choy a Fruit? Answer Yes or No.\", \"target\": \"No.\"},\n",
      "    {\"input\": \"Is Bak Kwa a Fruit? Answer Yes or No.\", \"target\": \"No.\"},\n",
      "    {\"input\": \"Is Dragonfruit a Fruit? Answer Yes or No.\", \"target\": \"Yes.\"},\n",
      "    {\"input\": \"Is Orange a Fruit? Answer Yes or No.\", \"target\": \"Yes.\"},\n",
      "    {\"input\": \"Is Coke Zero a Fruit? Answer Yes or No.\", \"target\": \"No.\"}\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"moonshot-data/datasets/fruits-csv-dataset.json\", \"r\") as json_file:\n",
    "    json_content = json_file.read()\n",
    "print(json_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42e123",
   "metadata": {},
   "source": [
    "### Download Hugging Face dataset to Moonshot dataset\n",
    "\n",
    "You can easily download a dataset from Hugging Face and convert it into a Moonshot dataset. \n",
    "\n",
    "This allows you to leverage the extensive collection of datasets available on Hugging Face for your benchmarking needs in Moonshot.\n",
    "\n",
    "By integrating Hugging Face datasets, you can expand the variety and scope of your tests, ensuring comprehensive evaluation of your models.\n",
    "\n",
    "Let's take a look at an example Hugging Face dataset:<br>\n",
    "https://huggingface.co/datasets/cais/mmlu\n",
    "\n",
    "You may use the full-screen viewer to have a closer look at the dataset:<br>\n",
    "https://huggingface.co/datasets/cais/mmlu/viewer/college_biology/dev\n",
    "\n",
    "There are multiple subsets (abstract_algebra, all, college_biology, ...), splits (test, validation, dev), columns to choose from:\n",
    "1. question (string)\n",
    "2. subject (string)\n",
    "3. choices (list)\n",
    "4. answer (string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e70d47",
   "metadata": {},
   "source": [
    "We will use the following provided `api_download_dataset` API function.\n",
    "\n",
    "- `name` (str): name of the data\n",
    "- `description` (str): description of the dataset\n",
    "- `reference` (str): a link/reference to where the dataset is from (or author of the dataset)\n",
    "- `license` (str): license of the data\n",
    "- `kwargs`: An additional keyword arguments for downloading the dataset from Hugging Face.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7adbb94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moonshot-data/datasets/college-biology-dataset.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_download_dataset(\n",
    "    name=\"College Biology Dataset\",\n",
    "    description=\"Multiple-choice questions from various branches of knowledge\",\n",
    "    reference=\"\",\n",
    "    license=\"MIT license\",\n",
    "    dataset_name='cais/mmlu',\n",
    "    dataset_config='college_biology',\n",
    "    split='dev',\n",
    "    input_col=['question', 'choices'],\n",
    "    target_col='answer'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3be4ff9",
   "metadata": {},
   "source": [
    "Let's take a look at what the converted dataset `college-biology-dataset.json` contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c32ffb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"college-biology-dataset\",\n",
      "  \"name\": \"College Biology Dataset\",\n",
      "  \"description\": \"Multiple-choice questions from various branches of knowledge\",\n",
      "  \"reference\": \"\",\n",
      "  \"license\": \"MIT license\",\n",
      "  \"examples\": [\n",
      "    {\"input\": \"Which of the following represents an accurate statement concerning arthropods? ['They possess an exoskeleton composed primarily of peptidoglycan.', 'They possess an open circulatory system with a dorsal heart.', 'They are members of a biologically unsuccessful phylum incapable of exploiting diverse habitats and nutrition sources.', 'They lack paired, jointed appendages.']\", \"target\": \"1\"},\n",
      "    {\"input\": \"In a given population, 1 out of every 400 people has a cancer caused by a completely recessive allele, b. Assuming the population is in Hardy-Weinberg equilibrium, which of the following is the expected proportion of individuals who carry the b allele but are not expected to develop the cancer? ['1/400', '19/400', '20/400', '38/400']\", \"target\": \"3\"},\n",
      "    {\"input\": \"The presence of homologous structures in two different organisms, such as the humerus in the front limb of a human and a bird, indicates that ['the human and bird are polyphyletic species', \\\"a human's and bird's evolution is convergent\\\", 'the human and bird belong to a clade', 'the human and bird developed by analogy']\", \"target\": \"2\"},\n",
      "    {\"input\": \"According to the pressure-flow model of movement of phloem contents, photosynthate movement from source to sink is driven by ['an ATP-dependent pressure-flow pump', 'a water-pressure potential gradient', 'transpiration', 'apoplastic diffusion']\", \"target\": \"1\"},\n",
      "    {\"input\": \"Which of the following contain DNA sequences required for the segregation of chromosomes in mitosis and meiosis? ['Telomeres', 'Centromeres', 'Nucleosomes', 'Spliceosomes']\", \"target\": \"1\"}\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"moonshot-data/datasets/college-biology-dataset.json\", \"r\") as json_file:\n",
    "    json_content = json_file.read()\n",
    "print(json_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7acdff5-c59c-4179-badb-ab68560793a6",
   "metadata": {},
   "source": [
    "## Create a new recipe\n",
    "\n",
    "To run this dataset, you need to create 2 new <b>recipes</b>.\n",
    "\n",
    "A <b>recipe</b> contains all the details required to run a benchmark.<br>\n",
    "A <b>recipe</b> guides Moonshot on what data to use, and how to evaluate the model's responses.\n",
    "\n",
    "To create a new <b>recipe</b>, you need the following elements:\n",
    "\n",
    "1. **Name**: A unique name for the recipe.\n",
    "2. **Description**: An explanation of what the recipe does and what it's for.\n",
    "3. **Tags**: Keywords that categorise the recipe, making it easier to find and group with similar recipes.\n",
    "4. **Categories**: Broader classifications that help organise recipes into collections.\n",
    "5. **Datasets**: The data that will be used when running the recipe. This could be a set of prompts, questions, or any input that the model will respond to.\n",
    "6. **Prompt Templates**: Pre-prompt or post-prompt static text that will be appended to the prompt.\n",
    "7. **Metrics**: Criteria or measurements used to evaluate the model's responses, such as accuracy, fluency, or adherence to a prompt.\n",
    "8. **Grading Scale**: A set of thresholds or criteria used to grade or score the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e855bb-1322-4cc5-b775-ddd0dcbdcfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe 'fruit-questions' has been created.\n"
     ]
    }
   ],
   "source": [
    "test_recipe = api_create_recipe(\n",
    "    \"Fruit Questions\", # name (mandatory)\n",
    "    \"This recipe is created to test model's ability in answering fruits question.\", # description (mandatory)\n",
    "    [\"chatbot\"], # tags (optional)\n",
    "    [\"capability\"], # category (optional)\n",
    "    [\"test-dataset\", \"fruits-csv-dataset\"], # filename of the dataset (mandatory)\n",
    "    [], # prompt templates (optional)\n",
    "    [\"exactstrmatch\", \"bertscore\" ], # metrics (mandatory)\n",
    "    { # grading scale (optional)\n",
    "        \"A\": [\n",
    "            80,\n",
    "            100\n",
    "        ],\n",
    "        \"B\": [\n",
    "            60,\n",
    "            79\n",
    "        ],\n",
    "        \"C\": [\n",
    "            40,\n",
    "            59\n",
    "        ],\n",
    "        \"D\": [\n",
    "            20,\n",
    "            39\n",
    "        ],\n",
    "        \"E\": [\n",
    "            0,\n",
    "            19\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Recipe '{test_recipe}' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0144899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe 'biology-questions' has been created.\n"
     ]
    }
   ],
   "source": [
    "test_college_recipe = api_create_recipe(\n",
    "    \"Biology Questions\", # name (mandatory)\n",
    "    \"This recipe is created to test model's ability in answering college biology question.\", # description (mandatory)\n",
    "    [\"chatbot\"], # tags (optional)\n",
    "    [\"capability\"], # category (optional)\n",
    "    [\"college-biology-dataset\"], # filename of the dataset (mandatory)\n",
    "    [], # prompt templates (optional)\n",
    "    [\"exactstrmatch\", \"bertscore\"], # metrics (mandatory)\n",
    "    { # grading scale (optional)\n",
    "        \"A\": [\n",
    "            80,\n",
    "            100\n",
    "        ],\n",
    "        \"B\": [\n",
    "            60,\n",
    "            79\n",
    "        ],\n",
    "        \"C\": [\n",
    "            40,\n",
    "            59\n",
    "        ],\n",
    "        \"D\": [\n",
    "            20,\n",
    "            39\n",
    "        ],\n",
    "        \"E\": [\n",
    "            0,\n",
    "            19\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Recipe '{test_college_recipe}' has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e7fdb-6de1-4f3a-ac71-9605256f7a29",
   "metadata": {},
   "source": [
    "## Run your new recipe\n",
    "\n",
    "With these new recipes, you can run this on your `connector endpoint`. We will run this on endpoint `my-openai-endpoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86c6164b-fc57-457a-a640-f11c451fcdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 14:06:18,529 [INFO][runner.py::run_recipes(349)] [Runner] my-new-recipe-runner - Running benchmark recipe run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 14:06:19,562 [INFO][benchmarking.py::generate(169)] [Benchmarking] Running recipes (['fruit-questions', 'biology-questions'])...\n",
      "2025-04-14 14:06:19,563 [INFO][benchmarking.py::generate(173)] [Benchmarking] Running recipe fruit-questions... (1/2)\n",
      "2025-04-14 14:06:28,034 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 1.\n",
      "2025-04-14 14:06:28,042 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 1.\n",
      "2025-04-14 14:06:34.539139: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744653994.664414   72750 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744653994.693122   72750 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 14:06:34.948296: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-04-14 14:06:46,806 [INFO][benchmarking.py::generate(173)] [Benchmarking] Running recipe biology-questions... (2/2)\n",
      "2025-04-14 14:06:46,862 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 1.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-04-14 14:06:50,991 [INFO][benchmarking.py::generate(203)] [Benchmarking] Run took 33.2956s\n",
      "2025-04-14 14:06:51,003 [INFO][benchmarking.py::generate(258)] [Benchmarking] Preparing results took 0.0010s\n",
      "2025-04-14 14:06:51,023 [INFO][benchmarking-result.py::generate(58)] [BenchmarkingResult] Generate results took 0.0191s\n",
      "2025-04-14 14:06:51,034 [INFO][runner.py::run_recipes(375)] [Runner] my-new-recipe-runner - Benchmark recipe run completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"id\": \"my-new-recipe-runner\",\n",
      "    \"start_time\": \"2025-04-14 14:06:18\",\n",
      "    \"end_time\": \"2025-04-14 14:06:50\",\n",
      "    \"duration\": 32,\n",
      "    \"status\": \"completed\",\n",
      "    \"recipes\": [\n",
      "      \"fruit-questions\",\n",
      "      \"biology-questions\"\n",
      "    ],\n",
      "    \"cookbooks\": null,\n",
      "    \"endpoints\": [\n",
      "      \"my-openai-endpoint\"\n",
      "    ],\n",
      "    \"prompt_selection_percentage\": 1,\n",
      "    \"random_seed\": 1,\n",
      "    \"system_prompt\": \"\"\n",
      "  },\n",
      "  \"results\": {\n",
      "    \"recipes\": [\n",
      "      {\n",
      "        \"id\": \"fruit-questions\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"model_id\": \"my-openai-endpoint\",\n",
      "            \"dataset_id\": \"fruits-csv-dataset\",\n",
      "            \"prompt_template_id\": \"no-template\",\n",
      "            \"data\": [\n",
      "              {\n",
      "                \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                \"predicted_result\": {\n",
      "                  \"response\": \"Yes\",\n",
      "                  \"context\": []\n",
      "                },\n",
      "                \"target\": \"Yes.\",\n",
      "                \"duration\": 1.351232307999453\n",
      "              }\n",
      "            ],\n",
      "            \"metrics\": [\n",
      "              {\n",
      "                \"exactstrmatch\": {\n",
      "                  \"accuracy\": 0.0,\n",
      "                  \"individual_scores\": {\n",
      "                    \"unsuccessful\": [\n",
      "                      {\n",
      "                        \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                        \"predicted_value\": \"Yes\",\n",
      "                        \"target\": \"Yes.\",\n",
      "                        \"eval\": \"wrong\"\n",
      "                      }\n",
      "                    ],\n",
      "                    \"successful\": []\n",
      "                  }\n",
      "                },\n",
      "                \"grading_criteria\": {\n",
      "                  \"accuracy\": 0.0\n",
      "                }\n",
      "              },\n",
      "              {\n",
      "                \"bertscore\": {\n",
      "                  \"precision\": 0.5543328523635864,\n",
      "                  \"recall\": 0.7769576907157898,\n",
      "                  \"f1\": 0.6639840602874756,\n",
      "                  \"individual_scores\": [\n",
      "                    {\n",
      "                      \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                      \"predicted_value\": \"Yes\",\n",
      "                      \"target\": \"Yes.\",\n",
      "                      \"score\": {\n",
      "                        \"precision\": 0.5543328523635864,\n",
      "                        \"recall\": 0.7769576907157898,\n",
      "                        \"f1\": 0.6639840602874756\n",
      "                      }\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"grading_criteria\": {}\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"model_id\": \"my-openai-endpoint\",\n",
      "            \"dataset_id\": \"test-dataset\",\n",
      "            \"prompt_template_id\": \"no-template\",\n",
      "            \"data\": [\n",
      "              {\n",
      "                \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                \"predicted_result\": {\n",
      "                  \"response\": \"Yes.\",\n",
      "                  \"context\": []\n",
      "                },\n",
      "                \"target\": \"Yes.\",\n",
      "                \"duration\": 0.9094784680019075\n",
      "              }\n",
      "            ],\n",
      "            \"metrics\": [\n",
      "              {\n",
      "                \"exactstrmatch\": {\n",
      "                  \"accuracy\": 100.0,\n",
      "                  \"individual_scores\": {\n",
      "                    \"unsuccessful\": [],\n",
      "                    \"successful\": [\n",
      "                      {\n",
      "                        \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                        \"predicted_value\": \"Yes.\",\n",
      "                        \"target\": \"Yes.\",\n",
      "                        \"eval\": \"correct\"\n",
      "                      }\n",
      "                    ]\n",
      "                  }\n",
      "                },\n",
      "                \"grading_criteria\": {\n",
      "                  \"accuracy\": 100.0\n",
      "                }\n",
      "              },\n",
      "              {\n",
      "                \"bertscore\": {\n",
      "                  \"precision\": 1.0,\n",
      "                  \"recall\": 1.0,\n",
      "                  \"f1\": 1.0,\n",
      "                  \"individual_scores\": [\n",
      "                    {\n",
      "                      \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                      \"predicted_value\": \"Yes.\",\n",
      "                      \"target\": \"Yes.\",\n",
      "                      \"score\": {\n",
      "                        \"precision\": 1.0,\n",
      "                        \"recall\": 1.0,\n",
      "                        \"f1\": 1.0\n",
      "                      }\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"grading_criteria\": {}\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"evaluation_summary\": [\n",
      "          {\n",
      "            \"model_id\": \"my-openai-endpoint\",\n",
      "            \"num_of_prompts\": 2,\n",
      "            \"avg_grade_value\": 50.0,\n",
      "            \"grade\": \"C\"\n",
      "          }\n",
      "        ],\n",
      "        \"grading_scale\": {\n",
      "          \"A\": [\n",
      "            80,\n",
      "            100\n",
      "          ],\n",
      "          \"B\": [\n",
      "            60,\n",
      "            79\n",
      "          ],\n",
      "          \"C\": [\n",
      "            40,\n",
      "            59\n",
      "          ],\n",
      "          \"D\": [\n",
      "            20,\n",
      "            39\n",
      "          ],\n",
      "          \"E\": [\n",
      "            0,\n",
      "            19\n",
      "          ]\n",
      "        },\n",
      "        \"total_num_of_prompts\": 2\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"biology-questions\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"model_id\": \"my-openai-endpoint\",\n",
      "            \"dataset_id\": \"college-biology-dataset\",\n",
      "            \"prompt_template_id\": \"no-template\",\n",
      "            \"data\": [\n",
      "              {\n",
      "                \"prompt\": \"In a given population, 1 out of every 400 people has a cancer caused by a completely recessive allele, b. Assuming the population is in Hardy-Weinberg equilibrium, which of the following is the expected proportion of individuals who carry the b allele but are not expected to develop the cancer? ['1/400', '19/400', '20/400', '38/400']\",\n",
      "                \"predicted_result\": {\n",
      "                  \"response\": \"To determine the expected proportion of individuals who carry the b allele but are not expected to develop the cancer, we first need to find the frequency of the b allele in the population.\\n\\nSince the cancer caused by the b allele is completely recessive, individuals must be homozygous for the b allele to develop the cancer. Therefore, the frequency of individuals who have the b allele but are not expected to develop the cancer is equal to the frequency of heterozygous individuals.\\n\\nLet's denote the frequency of the b allele as q. Since 1 out of every 400 people has the cancer caused by the b allele, the frequency of individuals who are homozygous for the b allele (q^2) is 1/400. Therefore, q^2 = 1/400.\\n\\nSince the population is in Hardy-Weinberg equilibrium, we know that p^2 + 2pq + q^2 = 1, where p is the frequency of the dominant allele and q is the frequency of the recessive allele.\\n\\nGiven that q^2 = 1/400, we can solve for q:\\n\\nq^2 = 1/400\\nq = sqrt(1/400)\\nq = 1/20\\nq = 1/20\\n\\nNow, we can calculate the frequency of heterozygous individuals (2pq):\\n\\n2pq = 2 * (1/20) * (19/20)\\n2pq = 38/400\\n\\nTherefore, the expected proportion of individuals who carry the b allele but are not expected to develop the cancer is 38/400.\",\n",
      "                  \"context\": []\n",
      "                },\n",
      "                \"target\": \"3\",\n",
      "                \"duration\": 3.043624259000353\n",
      "              }\n",
      "            ],\n",
      "            \"metrics\": [\n",
      "              {\n",
      "                \"exactstrmatch\": {\n",
      "                  \"accuracy\": 0.0,\n",
      "                  \"individual_scores\": {\n",
      "                    \"unsuccessful\": [\n",
      "                      {\n",
      "                        \"prompt\": \"In a given population, 1 out of every 400 people has a cancer caused by a completely recessive allele, b. Assuming the population is in Hardy-Weinberg equilibrium, which of the following is the expected proportion of individuals who carry the b allele but are not expected to develop the cancer? ['1/400', '19/400', '20/400', '38/400']\",\n",
      "                        \"predicted_value\": \"To determine the expected proportion of individuals who carry the b allele but are not expected to develop the cancer, we first need to find the frequency of the b allele in the population.\\n\\nSince the cancer caused by the b allele is completely recessive, individuals must be homozygous for the b allele to develop the cancer. Therefore, the frequency of individuals who have the b allele but are not expected to develop the cancer is equal to the frequency of heterozygous individuals.\\n\\nLet's denote the frequency of the b allele as q. Since 1 out of every 400 people has the cancer caused by the b allele, the frequency of individuals who are homozygous for the b allele (q^2) is 1/400. Therefore, q^2 = 1/400.\\n\\nSince the population is in Hardy-Weinberg equilibrium, we know that p^2 + 2pq + q^2 = 1, where p is the frequency of the dominant allele and q is the frequency of the recessive allele.\\n\\nGiven that q^2 = 1/400, we can solve for q:\\n\\nq^2 = 1/400\\nq = sqrt(1/400)\\nq = 1/20\\nq = 1/20\\n\\nNow, we can calculate the frequency of heterozygous individuals (2pq):\\n\\n2pq = 2 * (1/20) * (19/20)\\n2pq = 38/400\\n\\nTherefore, the expected proportion of individuals who carry the b allele but are not expected to develop the cancer is 38/400.\",\n",
      "                        \"target\": \"3\",\n",
      "                        \"eval\": \"wrong\"\n",
      "                      }\n",
      "                    ],\n",
      "                    \"successful\": []\n",
      "                  }\n",
      "                },\n",
      "                \"grading_criteria\": {\n",
      "                  \"accuracy\": 0.0\n",
      "                }\n",
      "              },\n",
      "              {\n",
      "                \"bertscore\": {\n",
      "                  \"precision\": -0.6834830641746521,\n",
      "                  \"recall\": -0.14140449464321136,\n",
      "                  \"f1\": -0.4263516068458557,\n",
      "                  \"individual_scores\": [\n",
      "                    {\n",
      "                      \"prompt\": \"In a given population, 1 out of every 400 people has a cancer caused by a completely recessive allele, b. Assuming the population is in Hardy-Weinberg equilibrium, which of the following is the expected proportion of individuals who carry the b allele but are not expected to develop the cancer? ['1/400', '19/400', '20/400', '38/400']\",\n",
      "                      \"predicted_value\": \"To determine the expected proportion of individuals who carry the b allele but are not expected to develop the cancer, we first need to find the frequency of the b allele in the population.\\n\\nSince the cancer caused by the b allele is completely recessive, individuals must be homozygous for the b allele to develop the cancer. Therefore, the frequency of individuals who have the b allele but are not expected to develop the cancer is equal to the frequency of heterozygous individuals.\\n\\nLet's denote the frequency of the b allele as q. Since 1 out of every 400 people has the cancer caused by the b allele, the frequency of individuals who are homozygous for the b allele (q^2) is 1/400. Therefore, q^2 = 1/400.\\n\\nSince the population is in Hardy-Weinberg equilibrium, we know that p^2 + 2pq + q^2 = 1, where p is the frequency of the dominant allele and q is the frequency of the recessive allele.\\n\\nGiven that q^2 = 1/400, we can solve for q:\\n\\nq^2 = 1/400\\nq = sqrt(1/400)\\nq = 1/20\\nq = 1/20\\n\\nNow, we can calculate the frequency of heterozygous individuals (2pq):\\n\\n2pq = 2 * (1/20) * (19/20)\\n2pq = 38/400\\n\\nTherefore, the expected proportion of individuals who carry the b allele but are not expected to develop the cancer is 38/400.\",\n",
      "                      \"target\": \"3\",\n",
      "                      \"score\": {\n",
      "                        \"precision\": -0.6834830641746521,\n",
      "                        \"recall\": -0.14140449464321136,\n",
      "                        \"f1\": -0.4263516068458557\n",
      "                      }\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"grading_criteria\": {}\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"evaluation_summary\": [\n",
      "          {\n",
      "            \"model_id\": \"my-openai-endpoint\",\n",
      "            \"num_of_prompts\": 1,\n",
      "            \"avg_grade_value\": 0.0,\n",
      "            \"grade\": \"E\"\n",
      "          }\n",
      "        ],\n",
      "        \"grading_scale\": {\n",
      "          \"A\": [\n",
      "            80,\n",
      "            100\n",
      "          ],\n",
      "          \"B\": [\n",
      "            60,\n",
      "            79\n",
      "          ],\n",
      "          \"C\": [\n",
      "            40,\n",
      "            59\n",
      "          ],\n",
      "          \"D\": [\n",
      "            20,\n",
      "            39\n",
      "          ],\n",
      "          \"E\": [\n",
      "            0,\n",
      "            19\n",
      "          ]\n",
      "        },\n",
      "        \"total_num_of_prompts\": 1\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from slugify import slugify\n",
    "from moonshot.api import api_get_all_run, api_create_runner, api_get_all_runner_name\n",
    "\n",
    "name = \"my new recipe runner\" # Indicate the name\n",
    "recipes = [\"fruit-questions\", \"biology-questions\"] # Test two recipes fruit-questions and biology-questions. You can add more recipes in the list to test as well\n",
    "endpoints = [\"my-openai-endpoint\"]  #Test against 1 endpoint, my-openai-endpoint\n",
    "prompt_selection_percentage = 1 # The percentage number of prompt(s) to run from EACH dataset in the recipe; this refers to 1% of each dataset prompts.\n",
    "\n",
    "# Below are the optional fields\n",
    "random_seed = 1   # Default: 0; this allows for randomness in dataset selection when prompt selection percentage are set\n",
    "system_prompt = \"\"  # Default: \"\"; this allows setting the system prompt for the endpoints\n",
    "\n",
    "# Advanced user - Modify runner processing module and result processing module\n",
    "# Default: benchmarking and benchmarking-result\n",
    "runner_proc_module = \"benchmarking\"  # Default: \"benchmarking\"\n",
    "result_proc_module = \"benchmarking-result\"  # Default: \"benchmarking-result\"\n",
    "\n",
    "# Run the recipe with the defined endpoint(s)\n",
    "# If the id exists, it will perform a load on the runner, instead of creating a new runner.\n",
    "# Using an existing runner allows the new run to possibly use cached results from previous runs, which greatly reduces the run time\n",
    "slugify_id = slugify(name, lowercase=True)\n",
    "if slugify_id in api_get_all_runner_name():\n",
    "    rec_runner = api_load_runner(slugify_id)\n",
    "else:\n",
    "    rec_runner = api_create_runner(name, endpoints)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# run_cookbooks is an async function. Currently there is no sync version.\n",
    "# We will get an existing event loop and execute the run cookbooks process.\n",
    "await rec_runner.run_recipes(\n",
    "    recipes,\n",
    "    prompt_selection_percentage,\n",
    "    random_seed,\n",
    "    system_prompt,\n",
    "    runner_proc_module,\n",
    "    result_proc_module,\n",
    ")\n",
    "await rec_runner.close()  # Perform a close on the runner to allow proper cleanup.\n",
    "\n",
    "# Display results\n",
    "runner_runs = api_get_all_run(rec_runner.id)\n",
    "result_info = runner_runs[-1].get(\"results\")\n",
    "if result_info:\n",
    "    print(json.dumps(result_info, indent=2))\n",
    "else:\n",
    "    raise RuntimeError(\"no run result generated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90595255-2237-40d7-a06b-90d526322a00",
   "metadata": {},
   "source": [
    "## Beautifying Test Results\n",
    "\n",
    "The result above is shown in our raw JSON file. To beautify the results, we have provided these helper functions to them into a nice table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ca3dd8-6b5a-479f-85b1-4e74f4482889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Recipes Result                                                   </span>\n",
       "┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> No. </span>┃<span style=\"font-weight: bold\"> Recipe                                                                              </span>┃<span style=\"font-weight: bold\"> my-openai-endpoint  </span>┃\n",
       "┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ 1   │ Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">fruit-questions</span>                                                             │      C [50.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│ 2   │ Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">biology-questions</span>                                                           │       E [0.0]       │\n",
       "└─────┴─────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Recipes Result                                                   \u001b[0m\n",
       "┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mNo.\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecipe                                                                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmy-openai-endpoint \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ 1   │ Recipe: \u001b[34mfruit-questions\u001b[0m                                                             │      C [50.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│ 2   │ Recipe: \u001b[34mbiology-questions\u001b[0m                                                           │       E [0.0]       │\n",
       "└─────┴─────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==================================================\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">Time taken to run: 32s</span>\n",
       "*Overall rating will be the lowest grade that the recipes have in each cookbook\n",
       "==================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==================================================\n",
       "\u001b[34mTime taken to run: 32s\u001b[0m\n",
       "*Overall rating will be the lowest grade that the recipes have in each cookbook\n",
       "==================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.columns import Columns\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "console = Console()\n",
    "\n",
    "def show_recipe_results(recipes, endpoints, recipe_results, duration):\n",
    "    \"\"\"\n",
    "    Show the results of the recipe benchmarking.\n",
    "\n",
    "    This function takes the recipes, endpoints, recipe results, results file, and duration as arguments.\n",
    "    If there are any recipe results, it generates a table to display them using the generate_recipe_table function.\n",
    "    It also prints the location of the results file and the time taken to run the benchmarking.\n",
    "    If there are no recipe results, it prints a message indicating that there are no results.\n",
    "\n",
    "    Args:\n",
    "        recipes (list): A list of recipes that were benchmarked.\n",
    "        endpoints (list): A list of endpoints that were used in the benchmarking.\n",
    "        recipe_results (dict): A dictionary with the results of the recipe benchmarking.\n",
    "        duration (float): The time taken to run the benchmarking in seconds.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if recipe_results:\n",
    "        # Display recipe results\n",
    "        generate_recipe_table(recipes, endpoints, recipe_results)\n",
    "    else:\n",
    "        console.print(\"[red]There are no results.[/red]\")\n",
    "\n",
    "    # Print run stats\n",
    "    console.print(f\"{'='*50}\\n[blue]Time taken to run: {duration}s[/blue]\\n*Overall rating will be the lowest grade that the recipes have in each cookbook\\n{'='*50}\")\n",
    "\n",
    "def generate_recipe_table(recipes: list, endpoints: list, results: dict) -> None:\n",
    "    \"\"\"\n",
    "    Generate and display a table of recipe results.\n",
    "\n",
    "    This function creates a table that lists the results of running recipes against various endpoints.\n",
    "    Each row in the table corresponds to a recipe, and each column corresponds to an endpoint.\n",
    "    The results include the grade and average grade value for each recipe-endpoint pair.\n",
    "\n",
    "    Args:\n",
    "        recipes (list): A list of recipe IDs that were benchmarked.\n",
    "        endpoints (list): A list of endpoint IDs against which the recipes were run.\n",
    "        results (dict): A dictionary containing the results of the benchmarking.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything. It prints the table to the console.\n",
    "    \"\"\"\n",
    "    # Create a table with a title and headers\n",
    "    table = Table(\n",
    "        title=\"Recipes Result\", show_lines=True, expand=True, header_style=\"bold\"\n",
    "    )\n",
    "    table.add_column(\"No.\", width=2)\n",
    "    table.add_column(\"Recipe\", justify=\"left\", width=78)\n",
    "    # Add a column for each endpoint\n",
    "    for endpoint in endpoints:\n",
    "        table.add_column(endpoint, justify=\"center\")\n",
    "\n",
    "    # Iterate over each recipe and populate the table with results\n",
    "    for index, recipe_id in enumerate(recipes, start=1):\n",
    "        # Attempt to find the result for the current recipe\n",
    "        recipe_result = next(\n",
    "            (\n",
    "                result\n",
    "                for result in results[\"results\"][\"recipes\"]\n",
    "                if result[\"id\"] == recipe_id\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        # If the result exists, extract and format the results for each endpoint\n",
    "        if recipe_result:\n",
    "            endpoint_results = []\n",
    "            for endpoint in endpoints:\n",
    "                # Find the evaluation summary for the endpoint\n",
    "                evaluation_summary = next(\n",
    "                    (\n",
    "                        eval_summary\n",
    "                        for eval_summary in recipe_result[\"evaluation_summary\"]\n",
    "                        if eval_summary[\"model_id\"] == endpoint\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "\n",
    "                # Format the grade and average grade value, or use \"-\" if not found\n",
    "                grade = \"-\"\n",
    "                if (\n",
    "                    evaluation_summary\n",
    "                    and \"grade\" in evaluation_summary\n",
    "                    and \"avg_grade_value\" in evaluation_summary\n",
    "                    and evaluation_summary[\"grade\"]\n",
    "                ):\n",
    "                    grade = f\"{evaluation_summary['grade']} [{evaluation_summary['avg_grade_value']}]\"\n",
    "                endpoint_results.append(grade)\n",
    "\n",
    "            # Add a row for the recipe with its results\n",
    "            table.add_row(\n",
    "                str(index),\n",
    "                f\"Recipe: [blue]{recipe_result['id']}[/blue]\",\n",
    "                *endpoint_results,\n",
    "                end_section=True,\n",
    "            )\n",
    "        else:\n",
    "            # If no result is found, add a row with placeholders\n",
    "            table.add_row(\n",
    "                str(index),\n",
    "                f\"Recipe: [blue]{recipe_id}[/blue]\",\n",
    "                *([\"-\"] * len(endpoints)),\n",
    "                end_section=True,\n",
    "            )\n",
    "\n",
    "    # Print the table to the console\n",
    "    console.print(table)\n",
    "\n",
    "if result_info:\n",
    "    show_recipe_results(\n",
    "            recipes, endpoints, result_info, result_info[\"metadata\"][\"duration\"]\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a28bf55-0e7e-4c2e-b372-97294e0e34eb",
   "metadata": {},
   "source": [
    "## Create a new `cookbook`\n",
    "\n",
    "We can also create a new `cookbook` and add existing recipes together with our new recipe. A `cookbook` in Moonshot is a curated collection of `recipes` designed to be executed together.\n",
    "\n",
    "To create a new cookbook, you need the following fields:\n",
    "\n",
    "1. **Name**: A unique name for the cookbook.\n",
    "2. **Description**: A detailed explanation of the cookbook's purpose and the recipe(s) it contains.\n",
    "3. **Recipes**: A list of recipe(s) that are included in the cookbook. Each recipe represents a specific test or benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "288bb18b-a5ee-49b6-97dd-7d33c336c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookbook 'test-cookbook' has been created.\n"
     ]
    }
   ],
   "source": [
    "cookbook_id = api_create_cookbook(\n",
    "    \"test-cookbook\",\n",
    "    \"This cookbook tests both fruits questions and general science questions.\",\n",
    "    [\"fruit-questions\"]\n",
    ")\n",
    "\n",
    "print(f\"Cookbook '{cookbook_id}' has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76208f03-e0a3-4d55-b565-267e1a847027",
   "metadata": {},
   "source": [
    "## Run your new cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b5b3ce-779c-47f8-94fc-9a2f2147236b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 14:09:04,288 [INFO][runner.py::run_cookbooks(412)] [Runner] test-new-cookbook - Running benchmark cookbook run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 14:09:04,423 [INFO][benchmarking.py::generate(139)] [Benchmarking] Running cookbooks (['test-cookbook'])...\n",
      "2025-04-14 14:09:04,424 [INFO][benchmarking.py::generate(145)] [Benchmarking] Running cookbook test-cookbook... (1/1)\n",
      "2025-04-14 14:09:04,450 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 1.\n",
      "2025-04-14 14:09:04,457 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 1.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-04-14 14:09:10,248 [INFO][benchmarking.py::generate(203)] [Benchmarking] Run took 7.6982s\n",
      "2025-04-14 14:09:10,260 [INFO][benchmarking.py::generate(258)] [Benchmarking] Preparing results took 0.0043s\n",
      "2025-04-14 14:09:10,277 [INFO][benchmarking-result.py::generate(58)] [BenchmarkingResult] Generate results took 0.0155s\n",
      "2025-04-14 14:09:10,286 [INFO][runner.py::run_cookbooks(438)] [Runner] test-new-cookbook - Benchmark cookbook run completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"id\": \"test-new-cookbook\",\n",
      "    \"start_time\": \"2025-04-14 14:09:04\",\n",
      "    \"end_time\": \"2025-04-14 14:09:10\",\n",
      "    \"duration\": 5,\n",
      "    \"status\": \"completed\",\n",
      "    \"recipes\": null,\n",
      "    \"cookbooks\": [\n",
      "      \"test-cookbook\"\n",
      "    ],\n",
      "    \"endpoints\": [\n",
      "      \"my-openai-endpoint\"\n",
      "    ],\n",
      "    \"prompt_selection_percentage\": 1,\n",
      "    \"random_seed\": 1,\n",
      "    \"system_prompt\": \"\"\n",
      "  },\n",
      "  \"results\": {\n",
      "    \"cookbooks\": [\n",
      "      {\n",
      "        \"id\": \"test-cookbook\",\n",
      "        \"recipes\": [\n",
      "          {\n",
      "            \"id\": \"fruit-questions\",\n",
      "            \"details\": [\n",
      "              {\n",
      "                \"model_id\": \"my-openai-endpoint\",\n",
      "                \"dataset_id\": \"fruits-csv-dataset\",\n",
      "                \"prompt_template_id\": \"no-template\",\n",
      "                \"data\": [\n",
      "                  {\n",
      "                    \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                    \"predicted_result\": {\n",
      "                      \"response\": \"Yes\",\n",
      "                      \"context\": []\n",
      "                    },\n",
      "                    \"target\": \"Yes.\",\n",
      "                    \"duration\": 1.4147682629991323\n",
      "                  }\n",
      "                ],\n",
      "                \"metrics\": [\n",
      "                  {\n",
      "                    \"exactstrmatch\": {\n",
      "                      \"accuracy\": 0.0,\n",
      "                      \"individual_scores\": {\n",
      "                        \"unsuccessful\": [\n",
      "                          {\n",
      "                            \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                            \"predicted_value\": \"Yes\",\n",
      "                            \"target\": \"Yes.\",\n",
      "                            \"eval\": \"wrong\"\n",
      "                          }\n",
      "                        ],\n",
      "                        \"successful\": []\n",
      "                      }\n",
      "                    },\n",
      "                    \"grading_criteria\": {\n",
      "                      \"accuracy\": 0.0\n",
      "                    }\n",
      "                  },\n",
      "                  {\n",
      "                    \"bertscore\": {\n",
      "                      \"precision\": 0.5543328523635864,\n",
      "                      \"recall\": 0.7769576907157898,\n",
      "                      \"f1\": 0.6639840602874756,\n",
      "                      \"individual_scores\": [\n",
      "                        {\n",
      "                          \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                          \"predicted_value\": \"Yes\",\n",
      "                          \"target\": \"Yes.\",\n",
      "                          \"score\": {\n",
      "                            \"precision\": 0.5543328523635864,\n",
      "                            \"recall\": 0.7769576907157898,\n",
      "                            \"f1\": 0.6639840602874756\n",
      "                          }\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    \"grading_criteria\": {}\n",
      "                  }\n",
      "                ]\n",
      "              },\n",
      "              {\n",
      "                \"model_id\": \"my-openai-endpoint\",\n",
      "                \"dataset_id\": \"test-dataset\",\n",
      "                \"prompt_template_id\": \"no-template\",\n",
      "                \"data\": [\n",
      "                  {\n",
      "                    \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                    \"predicted_result\": {\n",
      "                      \"response\": \"Yes\",\n",
      "                      \"context\": []\n",
      "                    },\n",
      "                    \"target\": \"Yes.\",\n",
      "                    \"duration\": 0.6969633369990333\n",
      "                  }\n",
      "                ],\n",
      "                \"metrics\": [\n",
      "                  {\n",
      "                    \"exactstrmatch\": {\n",
      "                      \"accuracy\": 0.0,\n",
      "                      \"individual_scores\": {\n",
      "                        \"unsuccessful\": [\n",
      "                          {\n",
      "                            \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                            \"predicted_value\": \"Yes\",\n",
      "                            \"target\": \"Yes.\",\n",
      "                            \"eval\": \"wrong\"\n",
      "                          }\n",
      "                        ],\n",
      "                        \"successful\": []\n",
      "                      }\n",
      "                    },\n",
      "                    \"grading_criteria\": {\n",
      "                      \"accuracy\": 0.0\n",
      "                    }\n",
      "                  },\n",
      "                  {\n",
      "                    \"bertscore\": {\n",
      "                      \"precision\": 0.5543328523635864,\n",
      "                      \"recall\": 0.7769576907157898,\n",
      "                      \"f1\": 0.6639840602874756,\n",
      "                      \"individual_scores\": [\n",
      "                        {\n",
      "                          \"prompt\": \"Is Apple a Fruit? Answer Yes or No.\",\n",
      "                          \"predicted_value\": \"Yes\",\n",
      "                          \"target\": \"Yes.\",\n",
      "                          \"score\": {\n",
      "                            \"precision\": 0.5543328523635864,\n",
      "                            \"recall\": 0.7769576907157898,\n",
      "                            \"f1\": 0.6639840602874756\n",
      "                          }\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    \"grading_criteria\": {}\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ],\n",
      "            \"evaluation_summary\": [\n",
      "              {\n",
      "                \"model_id\": \"my-openai-endpoint\",\n",
      "                \"num_of_prompts\": 2,\n",
      "                \"avg_grade_value\": 0.0,\n",
      "                \"grade\": \"E\"\n",
      "              }\n",
      "            ],\n",
      "            \"grading_scale\": {\n",
      "              \"A\": [\n",
      "                80,\n",
      "                100\n",
      "              ],\n",
      "              \"B\": [\n",
      "                60,\n",
      "                79\n",
      "              ],\n",
      "              \"C\": [\n",
      "                40,\n",
      "                59\n",
      "              ],\n",
      "              \"D\": [\n",
      "                20,\n",
      "                39\n",
      "              ],\n",
      "              \"E\": [\n",
      "                0,\n",
      "                19\n",
      "              ]\n",
      "            },\n",
      "            \"total_num_of_prompts\": 2\n",
      "          }\n",
      "        ],\n",
      "        \"overall_evaluation_summary\": [\n",
      "          {\n",
      "            \"model_id\": \"my-openai-endpoint\",\n",
      "            \"overall_grade\": \"E\"\n",
      "          }\n",
      "        ],\n",
      "        \"total_num_of_prompts\": 2\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from slugify import slugify\n",
    "from moonshot.api import api_get_all_run, api_create_runner, api_get_all_runner_name\n",
    "\n",
    "name = \"test new cookbook\" # Indicate the name\n",
    "cookbooks = [\"test-cookbook\"] # Test one cookbook test-cookbook. You can add more cookbooks in the list to test as well\n",
    "endpoints = [\"my-openai-endpoint\"] # Test against 1 endpoint, my-openai-endpoint\n",
    "prompt_selection_percentage = 1 # The percentage number of prompt(s) to run from EACH dataset in the cookbook; this refers to 1% of each dataset prompts.\n",
    "\n",
    "# Optional fields\n",
    "random_seed = 1   # Default: 0; this allows for randomness in dataset selection when prompt selection percentage are set\n",
    "system_prompt = \"\"  # Default: \"\"; this allows setting the system prompt for the endpoints\n",
    "\n",
    "# Advanced user - Modify runner processing module and result processing module\n",
    "# Default: benchmarking and benchmarking-result. Change it to your module name if you have your own runner and/or result module\n",
    "runner_proc_module = \"benchmarking\"  # Default: \"benchmarking\"\n",
    "result_proc_module = \"benchmarking-result\"  # Default: \"benchmarking-result\"\n",
    "\n",
    "# Run the cookbooks with the defined endpoint(s)\n",
    "# If the id exists, it will perform a load on the runner, instead of creating a new runner.\n",
    "# Using an existing runner allows the new run to possibly use cached results from previous runs, which greatly reduces the run time\n",
    "slugify_id = slugify(name, lowercase=True)\n",
    "if slugify_id in api_get_all_runner_name():\n",
    "    cb_runner = api_load_runner(slugify_id)\n",
    "else:\n",
    "    cb_runner = api_create_runner(name, endpoints)\n",
    "\n",
    "# run_cookbooks() is an async function. Currently there is no sync version\n",
    "# We will get an existing event loop and execute the run cookbooks process\n",
    "await cb_runner.run_cookbooks(\n",
    "        cookbooks,\n",
    "        prompt_selection_percentage,\n",
    "        random_seed,\n",
    "        system_prompt,\n",
    "        runner_proc_module,\n",
    "        result_proc_module,\n",
    "    )\n",
    "await cb_runner.close()  # Perform a close on the runner to allow proper cleanup.\n",
    "\n",
    "# Display results\n",
    "runner_runs = api_get_all_run(cb_runner.id)\n",
    "result_info = runner_runs[-1].get(\"results\")\n",
    "if result_info:\n",
    "    print(json.dumps(result_info, indent=2))\n",
    "else:\n",
    "    raise RuntimeError(\"no run result generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2ab13-bf8c-401b-a0f5-b59339fe0749",
   "metadata": {},
   "source": [
    "## Beautifying Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3adebeba-18b1-4fd6-8e95-b705d24f769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Cookbook Result                                                  </span>\n",
       "┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> No. </span>┃<span style=\"font-weight: bold\"> Cookbook (with its recipes)                                                         </span>┃<span style=\"font-weight: bold\"> my-openai-endpoint  </span>┃\n",
       "┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ 1   │ Cookbook: <span style=\"color: #000080; text-decoration-color: #000080\">test-cookbook</span>                                                             │          E          │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">fruit-questions</span>                                                      │       E [0.0]       │\n",
       "└─────┴─────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Cookbook Result                                                  \u001b[0m\n",
       "┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mNo.\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCookbook (with its recipes)                                                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmy-openai-endpoint \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ 1   │ Cookbook: \u001b[34mtest-cookbook\u001b[0m                                                             │          E          │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: \u001b[34mfruit-questions\u001b[0m                                                      │       E [0.0]       │\n",
       "└─────┴─────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==================================================\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">Time taken to run: 5s</span>\n",
       "*Overall rating will be the lowest grade that the recipes have in each cookbook\n",
       "==================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==================================================\n",
       "\u001b[34mTime taken to run: 5s\u001b[0m\n",
       "*Overall rating will be the lowest grade that the recipes have in each cookbook\n",
       "==================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.columns import Columns\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "console = Console()\n",
    "\n",
    "def show_cookbook_results(cookbooks, endpoints, cookbook_results, duration):\n",
    "    \"\"\"\n",
    "    Show the results of the cookbook benchmarking.\n",
    "\n",
    "    This function takes the cookbooks, endpoints, cookbook results, results file, and duration as arguments.\n",
    "    If there are results, it generates a table with the cookbook results and prints a message indicating\n",
    "    where the results are saved. If there are no results, it prints a message indicating that no results were found.\n",
    "    Finally, it prints the duration of the run.\n",
    "\n",
    "    Args:\n",
    "        cookbooks (list): A list of cookbooks.\n",
    "        endpoints (list): A list of endpoints.\n",
    "        cookbook_results (dict): A dictionary with the results of the cookbook benchmarking.\n",
    "        duration (float): The duration of the run.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if cookbook_results:\n",
    "        # Display recipe results\n",
    "        generate_cookbook_table(cookbooks, endpoints, cookbook_results)\n",
    "    else:\n",
    "        console.print(\"[red]There are no results.[/red]\")\n",
    "\n",
    "    # Print run stats\n",
    "    console.print(f\"{'='*50}\\n[blue]Time taken to run: {duration}s[/blue]\\n*Overall rating will be the lowest grade that the recipes have in each cookbook\\n{'='*50}\")\n",
    "\n",
    "def generate_cookbook_table(cookbooks: list, endpoints: list, results: dict) -> None:\n",
    "    \"\"\"\n",
    "    Generate and display a table with the cookbook benchmarking results.\n",
    "\n",
    "    This function creates a table that includes the index, cookbook name, recipe name, and the results\n",
    "    for each endpoint.\n",
    "\n",
    "    The cookbook names are prefixed with \"Cookbook:\" and are displayed with their overall grades. Each recipe under a\n",
    "    cookbook is indented and prefixed with \"Recipe:\" followed by its individual grades for each endpoint. If there are\n",
    "    no results for a cookbook, a row with dashes across all endpoint columns is added to indicate this.\n",
    "\n",
    "    Args:\n",
    "        cookbooks (list): A list of cookbook names to display in the table.\n",
    "        endpoints (list): A list of endpoints for which results are to be displayed.\n",
    "        results (dict): A dictionary containing the benchmarking results for cookbooks and recipes.\n",
    "\n",
    "    Returns:\n",
    "        None: The function prints the table to the console but does not return any value.\n",
    "    \"\"\"\n",
    "    table = Table(\n",
    "        title=\"Cookbook Result\", show_lines=True, expand=True, header_style=\"bold\"\n",
    "    )\n",
    "    table.add_column(\"No.\", width=2)\n",
    "    table.add_column(\"Cookbook (with its recipes)\", justify=\"left\", width=78)\n",
    "    for endpoint in endpoints:\n",
    "        table.add_column(endpoint, justify=\"center\")\n",
    "\n",
    "    index = 1\n",
    "    for cookbook in cookbooks:\n",
    "        # Get cookbook result\n",
    "        cookbook_result = next(\n",
    "            (\n",
    "                result\n",
    "                for result in results[\"results\"][\"cookbooks\"]\n",
    "                if result[\"id\"] == cookbook\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        if cookbook_result:\n",
    "            # Add the cookbook name with the \"Cookbook: \" prefix as the first row for this section\n",
    "            endpoint_results = []\n",
    "            for endpoint in endpoints:\n",
    "                # Find the evaluation summary for the endpoint\n",
    "                evaluation_summary = next(\n",
    "                    (\n",
    "                        temp_eval\n",
    "                        for temp_eval in cookbook_result[\"overall_evaluation_summary\"]\n",
    "                        if temp_eval[\"model_id\"] == endpoint\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "\n",
    "                # Get the grade from the evaluation_summary, or use \"-\" if not found\n",
    "                grade = \"-\"\n",
    "                if evaluation_summary and evaluation_summary[\"overall_grade\"]:\n",
    "                    grade = evaluation_summary[\"overall_grade\"]\n",
    "                endpoint_results.append(grade)\n",
    "            table.add_row(\n",
    "                str(index),\n",
    "                f\"Cookbook: [blue]{cookbook}[/blue]\",\n",
    "                *endpoint_results,\n",
    "                end_section=True,\n",
    "            )\n",
    "\n",
    "            for recipe in cookbook_result[\"recipes\"]:\n",
    "                endpoint_results = []\n",
    "                for endpoint in endpoints:\n",
    "                    # Find the evaluation summary for the endpoint\n",
    "                    evaluation_summary = next(\n",
    "                        (\n",
    "                            temp_eval\n",
    "                            for temp_eval in recipe[\"evaluation_summary\"]\n",
    "                            if temp_eval[\"model_id\"] == endpoint\n",
    "                        ),\n",
    "                        None,\n",
    "                    )\n",
    "\n",
    "                    # Get the grade from the evaluation_summary, or use \"-\" if not found\n",
    "                    grade = \"-\"\n",
    "                    if (\n",
    "                        evaluation_summary\n",
    "                        and \"grade\" in evaluation_summary\n",
    "                        and \"avg_grade_value\" in evaluation_summary\n",
    "                        and evaluation_summary[\"grade\"]\n",
    "                    ):\n",
    "                        grade = f\"{evaluation_summary['grade']} [{evaluation_summary['avg_grade_value']}]\"\n",
    "                    endpoint_results.append(grade)\n",
    "\n",
    "                # Add the recipe name indented under the cookbook name\n",
    "                table.add_row(\n",
    "                    \"\",\n",
    "                    f\"  └──  Recipe: [blue]{recipe['id']}[/blue]\",\n",
    "                    *endpoint_results,\n",
    "                    end_section=True,\n",
    "                )\n",
    "\n",
    "            # Increment index only after all recipes of the cookbook have been added\n",
    "            index += 1\n",
    "        else:\n",
    "            # If no results for the cookbook, add a row indicating this with the \"Cookbook: \" prefix\n",
    "            # and a dash for each endpoint column\n",
    "            table.add_row(\n",
    "                str(index),\n",
    "                f\"Cookbook: {cookbook}\",\n",
    "                *([\"-\"] * len(endpoints)),\n",
    "                end_section=True,\n",
    "            )\n",
    "            index += 1\n",
    "\n",
    "    # Display table\n",
    "    console.print(table)\n",
    "\n",
    "if result_info:\n",
    "    show_cookbook_results(\n",
    "        cookbooks, endpoints, result_info, result_info[\"metadata\"][\"duration\"]\n",
    "    )\n",
    "else:\n",
    "    raise RuntimeError(\"no run result generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
